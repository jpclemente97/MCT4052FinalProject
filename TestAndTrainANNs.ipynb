{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c0fa013",
   "metadata": {},
   "source": [
    "# Test and Train ANNs\n",
    "\n",
    "This notebook will train and test an MLP classifier and 9 MLP regressors (1 for each drummer). The classifier will classifer what drummer is playing based on microtiming and velocity, and the regressors will predict microtiming histogram values based on velocity histogram values for each drummer. The outputs will be a joblib file for the classifier pipeline and CSV files containing histogram bin percentages for velocity and microtiming for drummers 3, 7, 9 (which were shown to have the best results)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7789088e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import IPython.display\n",
    "import os\n",
    "from mido import MidiFile\n",
    "import sklearn\n",
    "import joblib\n",
    "from classes import Note\n",
    "from classes import File\n",
    "from classes import Drummer\n",
    "from functions import extractMidiData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e414142",
   "metadata": {},
   "source": [
    "# Extract MIDI Data From Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28b211f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "drummerNameToInt = {\n",
    "    \"drummer1\": 1,\n",
    "    \"drummer3\": 3,\n",
    "    \"drummer4\": 4,\n",
    "    \"drummer5\": 5,\n",
    "    \"drummer6\": 6,\n",
    "    \"drummer7\": 7,\n",
    "    \"drummer8\": 8,\n",
    "    \"drummer9\": 9,\n",
    "    \"drummer10\": 10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ce9b64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "drummers = os.listdir('./extendedGroove')\n",
    "\n",
    "drummersList = []\n",
    "\n",
    "# Keeping track of the number of files available, not all will be included all the time because\n",
    "# I will be focusing on files that have snare, hi-hats, and bass drum notes \n",
    "maxNumberOfFiles = 0\n",
    "\n",
    "for drummer in drummers:\n",
    "    if drummer.find('drummer') != -1:\n",
    "        filesList = []\n",
    "        sessions = os.listdir('./extendedGroove/' + drummer)\n",
    "        for session in sessions:\n",
    "            if session != '.DS_Store' and session != 'Icon\\r' and session != \"eval_session\":\n",
    "                files = os.listdir('./extendedGroove/' + drummer + '/' + session)\n",
    "                for file in files:\n",
    "                    if file.endswith('.midi'):\n",
    "                        maxNumberOfFiles += 1\n",
    "                        filePath = './extendedGroove/' + drummer + \"/\" + session + \"/\"  + file\n",
    "                        filesList.append(extractMidiData(filePath))\n",
    "        \n",
    "        drummersList.append(Drummer(drummer, drummerNameToInt[drummer], filesList))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17b709d",
   "metadata": {},
   "source": [
    "# Train and Run Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efc08da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOfFeatures = 78\n",
    "features = np.zeros((maxNumberOfFiles, numberOfFeatures)) \n",
    "labels = np.zeros((maxNumberOfFiles))\n",
    "fileIndex = 0\n",
    "for i, drummer in enumerate(drummersList):\n",
    "    for file in drummer.files:\n",
    "        velocities, microtimings = file.extractFeatures()\n",
    "        if not isinstance(velocities, int):\n",
    "            features[fileIndex, :] = np.concatenate((velocities, microtimings))\n",
    "            labels[fileIndex] = drummer.num\n",
    "            fileIndex += 1\n",
    "            \n",
    "features = np.resize(features, (fileIndex, numberOfFeatures))\n",
    "labels = np.resize(labels, (fileIndex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49ace659",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "classifierPipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('classifier', MLPClassifier(hidden_layer_sizes=(10,5), max_iter=5000, activation='relu'))\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d79b093",
   "metadata": {},
   "source": [
    "# Validate Classfier with 10 Cross-Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2cc1147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([13.90044188,  8.06874895, 14.06949306,  8.08291674, 10.98228788,\n",
      "       13.21937513, 13.37972116,  8.65519094, 14.44682884,  7.98129916]), 'score_time': array([0.0234282 , 0.00427508, 0.00454617, 0.00426602, 0.00452709,\n",
      "       0.00459099, 0.00481105, 0.00426292, 0.00436592, 0.00434899]), 'test_f1_macro': array([0.80275922, 0.99783285, 0.987829  , 0.99832975, 0.99302094,\n",
      "       0.96144925, 0.96064021, 0.99839471, 0.99394161, 0.99866553]), 'train_f1_macro': array([0.99942871, 0.99991559, 0.9992812 , 0.99926167, 0.9987962 ,\n",
      "       0.98031404, 0.98243608, 1.        , 0.99711083, 0.99979304]), 'test_accuracy': array([0.77791667, 0.99833333, 0.99375   , 0.99916632, 0.99749896,\n",
      "       0.99249687, 0.99249687, 0.9979158 , 0.99833264, 0.99874948]), 'train_accuracy': array([0.99986107, 0.99990738, 0.99981475, 0.99990738, 0.99962953,\n",
      "       0.99680467, 0.99689729, 1.        , 0.9994906 , 0.99986107])} \n",
      "\n",
      "Accuracy mean and variance 0.974665694039183 0.004307280847466153 \n",
      "\n",
      "F1 macro mean and variance 0.9692863062455255 0.003275135817591226 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = sklearn.model_selection.cross_validate(classifierPipe, features, labels, cv=10,scoring=('f1_macro', 'accuracy'),return_train_score=True)\n",
    "\n",
    "print(scores,'\\n')\n",
    "print('Accuracy mean and variance', np.mean(scores['test_accuracy']),np.var(scores['test_accuracy']),'\\n')\n",
    "print('F1 macro mean and variance', np.mean(scores['test_f1_macro']),np.var(scores['test_f1_macro']),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ad6356",
   "metadata": {},
   "source": [
    "# Train Model to Save for Later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f01f028f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['classifierPipe.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "feat_train, feat_test, lab_train, lab_test = train_test_split(features, labels, test_size=0.2)\n",
    "classifierPipe.fit(feat_train, lab_train)\n",
    "\n",
    "joblib.dump(classifierPipe, \"classifierPipe.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db271213",
   "metadata": {},
   "source": [
    "# Train and Run Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da03ee34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drummer8\n",
      "number of files:1143\n",
      "Mean squared error mean and variance -0.00022017367811193986 1.301752089296572e-07 \n",
      "\n",
      "Median absolute error mean and variance -0.002800583341305232 7.766709283642221e-07 \n",
      "\n",
      "R2 mean and variance 0.7247221722002608 0.168542259999715 \n",
      "\n",
      "Explained variance mean and variance 0.7318973915267653 0.15864751211398426 \n",
      "\n",
      "drummer6\n",
      "number of files:584\n",
      "Mean squared error mean and variance -0.0008559179585538737 3.018480738543205e-06 \n",
      "\n",
      "Median absolute error mean and variance -0.001561138319640196 4.437349561687285e-07 \n",
      "\n",
      "R2 mean and variance -4.235696813446863 198.1124226421635 \n",
      "\n",
      "Explained variance mean and variance -4.063860735138258 185.09191008773485 \n",
      "\n",
      "drummer1\n",
      "number of files:9833\n",
      "Mean squared error mean and variance -0.00304426386958469 7.709636983667285e-05 \n",
      "\n",
      "Median absolute error mean and variance -0.011712359303005977 0.0003816180185746883 \n",
      "\n",
      "R2 mean and variance 0.5210214428260463 2.0137105616131157 \n",
      "\n",
      "Explained variance mean and variance 0.6263772288284811 1.2178619455576905 \n",
      "\n",
      "drummer7\n",
      "number of files:7337\n",
      "Mean squared error mean and variance -0.0005431637386662395 1.9418376682709349e-07 \n",
      "\n",
      "Median absolute error mean and variance -0.00821565065918257 8.91102601628409e-06 \n",
      "\n",
      "R2 mean and variance 0.953996073804339 0.0018566907048505406 \n",
      "\n",
      "Explained variance mean and variance 0.9560241369739171 0.0017108689223934628 \n",
      "\n",
      "drummer10\n",
      "number of files:373\n",
      "Mean squared error mean and variance -0.00028989367934960754 4.958558649778605e-07 \n",
      "\n",
      "Median absolute error mean and variance -0.0008179262517295898 1.2253188185680337e-08 \n",
      "\n",
      "R2 mean and variance 0.7344979190861084 0.42039390541907745 \n",
      "\n",
      "Explained variance mean and variance 0.7431840730324805 0.39205995115568104 \n",
      "\n",
      "drummer9\n",
      "number of files:1104\n",
      "Mean squared error mean and variance -2.6361654667606916e-05 4.078363909427066e-10 \n",
      "\n",
      "Median absolute error mean and variance -0.0011552031756067304 1.4555172651172558e-08 \n",
      "\n",
      "R2 mean and variance 0.9941456034368971 1.7928220002635777e-05 \n",
      "\n",
      "Explained variance mean and variance 0.9942054362101848 1.7498849660274247e-05 \n",
      "\n",
      "drummer5\n",
      "number of files:1828\n",
      "Mean squared error mean and variance -0.0008210472419026253 1.6438587932576504e-07 \n",
      "\n",
      "Median absolute error mean and variance -0.0034102176153106302 3.5100017555379597e-07 \n",
      "\n",
      "R2 mean and variance -1.9605897798268437 2.779438004701399 \n",
      "\n",
      "Explained variance mean and variance -1.931870117365755 2.7265933110850242 \n",
      "\n",
      "drummer4\n",
      "number of files:170\n",
      "Mean squared error mean and variance -0.0004910702590797029 1.7613007086768492e-06 \n",
      "\n",
      "Median absolute error mean and variance -0.0019146691499571382 1.3533144484342888e-07 \n",
      "\n",
      "R2 mean and variance 0.3736933962128168 2.6114849954407955 \n",
      "\n",
      "Explained variance mean and variance 0.41092353075279275 2.3093765257963534 \n",
      "\n",
      "drummer3\n",
      "number of files:1621\n",
      "Mean squared error mean and variance -0.00016093561383311988 1.0732456977211592e-07 \n",
      "\n",
      "Median absolute error mean and variance -0.0030300783387604904 2.370952931863474e-06 \n",
      "\n",
      "R2 mean and variance 0.976793030832275 0.0013239147755661953 \n",
      "\n",
      "Explained variance mean and variance 0.9787964523129385 0.0013480799583097305 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "numberOfFeatures = 48\n",
    "numberOfTargets = 30\n",
    "\n",
    "for i, drummer in enumerate(drummersList):\n",
    "    features = np.zeros((maxNumberOfFiles, numberOfFeatures)) \n",
    "    targets = np.zeros((maxNumberOfFiles, numberOfTargets))\n",
    "    fileIndex = 0\n",
    "    for file in drummer.files:\n",
    "        velocities, microtimings = file.extractFeatures()\n",
    "        if not isinstance(velocities, int):\n",
    "            features[fileIndex, :] = velocities\n",
    "            targets[fileIndex, :] = microtimings\n",
    "            fileIndex += 1\n",
    "\n",
    "    features = np.resize(features, (fileIndex, numberOfFeatures))\n",
    "    targets = np.resize(targets, (fileIndex, numberOfTargets))\n",
    "    \n",
    "    pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('regressor', MLPRegressor(hidden_layer_sizes=(200,100,50), max_iter=5000, tol=0.0000001, activation='tanh'))\n",
    "        ])\n",
    "    \n",
    "    scores = sklearn.model_selection.cross_validate(pipe, features, targets, cv=10, scoring=('neg_mean_squared_error', 'neg_median_absolute_error', 'r2', 'explained_variance'), return_train_score=True)\n",
    "    print(drummer.name)\n",
    "    print(\"number of files:\" + str(fileIndex))\n",
    "    print('Mean squared error mean and variance', np.mean(scores['test_neg_mean_squared_error']),np.var(scores['test_neg_mean_squared_error']),'\\n')\n",
    "    print('Median absolute error mean and variance', np.mean(scores['test_neg_median_absolute_error']),np.var(scores['test_neg_median_absolute_error']),'\\n')\n",
    "    print('R2 mean and variance', np.mean(scores['test_r2']),np.var(scores['test_r2']),'\\n')\n",
    "    print('Explained variance mean and variance', np.mean(scores['test_explained_variance']),np.var(scores['test_explained_variance']),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71361b1",
   "metadata": {},
   "source": [
    "# Generate MIDI \n",
    "\n",
    "Through repeated testing, drummer7, drummer9, and drummer3 were found to have the best, most consistent results (high r2 scores). Therefore, only these three drummers will have CSV files generated for them to use to generate MIDI in the midi.py python file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08de600e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drummer7\n",
      "number of files:7337\n",
      "Mean squared error: 0.0002\n",
      "Mean absolute error: 0.0068\n",
      "Coefficient of determination (R2 score): 0.9871\n",
      "Explained variance score: 0.9873\n",
      "R2 score on individual targets [0.98742443 0.96268569 0.98167019 0.98838232 0.99134503 0.98886871\n",
      " 0.9897513  0.98831038 0.99388701 0.9894396  0.98908558 0.9911004\n",
      " 0.99022776 0.96518424 0.98604452 0.9977991  0.99236185 0.98754653\n",
      " 0.98462413 0.990326   0.98766936 0.98812296 0.99319373 0.99089754\n",
      " 0.97782143 0.97978438 0.98549155 0.99139512 0.99254514 0.99004696]\n",
      "drummer9\n",
      "number of files:1104\n",
      "Mean squared error: 0.0000\n",
      "Mean absolute error: 0.0024\n",
      "Coefficient of determination (R2 score): 0.9953\n",
      "Explained variance score: 0.9954\n",
      "R2 score on individual targets [0.99066513 0.99184607 0.99446545 0.99223017 0.99616538 0.9919786\n",
      " 0.99633957 0.99575436 0.99758029 0.99509047 0.99612671 0.99282624\n",
      " 0.99478749 0.98990414 0.99459213 0.99904942 0.98912187 0.98976317\n",
      " 0.99735075 0.99633459 0.9948145  0.99883011 0.99510753 0.99871922\n",
      " 0.99815852 0.99922343 0.99964831 0.99890164 0.99763236 0.99608939]\n",
      "drummer3\n",
      "number of files:1621\n",
      "Mean squared error: 0.0015\n",
      "Mean absolute error: 0.0055\n",
      "Coefficient of determination (R2 score): 0.8657\n",
      "Explained variance score: 0.8661\n",
      "R2 score on individual targets [0.67937753 0.88448864 0.9657912  0.95689612 0.97232855 0.51765489\n",
      " 0.99321289 0.96926697 0.91210945 0.83678594 0.93867558 0.94017281\n",
      " 0.73619991 0.71492331 0.82269499 0.98185898 0.95769818 0.94549197\n",
      " 0.89245062 0.9588304  0.77791847 0.98010944 0.98802646 0.99870367\n",
      " 0.22504313 0.98086111 0.91972112 0.82283813 0.9777352  0.72282106]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "numberOfFeatures = 48\n",
    "numberOfTargets = 30\n",
    "\n",
    "for i, drummer in enumerate(drummersList):\n",
    "    # Extract features the same way as before\n",
    "    if(drummer.name == \"drummer3\") or (drummer.name == \"drummer9\") or (drummer.name == \"drummer7\"):\n",
    "        features = np.zeros((maxNumberOfFiles, numberOfFeatures)) \n",
    "        targets = np.zeros((maxNumberOfFiles, numberOfTargets))\n",
    "        fileIndex = 0\n",
    "        for file in drummer.files:\n",
    "            velocities, microtimings = file.extractFeatures()\n",
    "            if not isinstance(velocities, int):\n",
    "                features[fileIndex, :] = velocities\n",
    "                targets[fileIndex, :] = microtimings\n",
    "                fileIndex += 1\n",
    "\n",
    "        features = np.resize(features, (fileIndex, numberOfFeatures))\n",
    "        targets = np.resize(targets, (fileIndex, numberOfTargets))\n",
    "        feat_train, feat_test, tar_train, tar_test = train_test_split(features, targets, test_size=0.2)\n",
    "        \n",
    "        # train and test regressor\n",
    "        pipe = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('regressor', MLPRegressor(hidden_layer_sizes=(200,100,50), max_iter=5000, tol=0.0000001, activation='tanh'))\n",
    "            ])\n",
    "\n",
    "        drummer.setRegressorPipe(pipe)\n",
    "        drummer.regressorPipe.fit(feat_train, tar_train)\n",
    "        tar_pred = drummer.regressorPipe.predict(feat_test)\n",
    "        \n",
    "        # Write the first microtiming and velocity values to CSV files to use in midi.py\n",
    "        snareMtCol, bassDrumMtCol, hihatMtCol = np.split(tar_pred[0], 3)\n",
    "        dfDict = {\n",
    "            'snareMicrotiming': snareMtCol,\n",
    "            'bassDrumMicrotiming': bassDrumMtCol,\n",
    "            'hihatMicrotiming': hihatMtCol,\n",
    "        }\n",
    "        df = pd.DataFrame(dfDict)\n",
    "        df.to_csv(drummer.name + 'Microtiming.csv')\n",
    "        \n",
    "        snareVelocityCol, bassDrumVelocityCol, hihatVelocityCol = np.split(feat_test[0, :48], 3)\n",
    "        dfDict = {\n",
    "            'snareVelocity': snareVelocityCol,\n",
    "            'bassDrumVelocity': bassDrumVelocityCol,\n",
    "            'hihatVelocity': hihatVelocityCol,\n",
    "        }\n",
    "        \n",
    "        df = pd.DataFrame(dfDict)\n",
    "        df.to_csv(drummer.name + 'Velocity.csv')\n",
    "        \n",
    "        # Print results\n",
    "        print(drummer.name)\n",
    "        print(\"number of files:\" + str(fileIndex))\n",
    "        \n",
    "        print('Mean squared error: %.4f'% sklearn.metrics.mean_squared_error(tar_test, tar_pred))\n",
    "        print('Mean absolute error: %.4f'% sklearn.metrics.mean_absolute_error(tar_test, tar_pred))\n",
    "        print('Coefficient of determination (R2 score): %.4f'% sklearn.metrics.r2_score(tar_test, tar_pred))\n",
    "        print('Explained variance score: %.4f'% sklearn.metrics.explained_variance_score(tar_test, tar_pred))\n",
    "        print('R2 score on individual targets',sklearn.metrics.r2_score(tar_test, tar_pred, multioutput='raw_values') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f02e7f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
